# Deepfake Audio Detection

## ðŸ“Œ Overview
This project focuses on detecting **audio deepfakes** â€” synthetic voices generated by advanced AI models that threaten security, trust, and authentication systems. We compare **classical machine learning** and **deep learning** approaches for reliable detection in real-world conditions.

## ðŸš€ Methods
We employ three complementary detection strategies:


1. **CQCC + GMM**  
   - Extract Constant-Q Cepstral Coefficients (CQCCs).  
   - Classify using Gaussian Mixture Models (GMMs) with log-likelihood ratios.  
   - âœ… Robust, inherits strengths from traditional anti-spoofing.

2. **CNN + Mel-Spectrograms**  
   - Convert audio into Mel-spectrograms.  
   - Train a Convolutional Neural Network (CNN) for end-to-end learning.  
   - âœ… State-of-the-art accuracy.

## ðŸ“Š Results
- **CNN**: Achieves highest accuracy on the *In-the-Wild* dataset.  
- **CQCC-GMM**: Provides robustness against varied spoofing conditions.  

ðŸ‘‰ Together, these approaches illustrate the **trade-off between classical ML and deep learning** in audio deepfake detection.

## ðŸ”‘ Keywords
- Audio Deepfake Detection  
- Voice Spoofing  
- Support Vector Machine (SVM)  

To run the code: activate the environment â†’ `source venv/bin/activate` (or `venv\Scripts\activate` on Windows), then run â†’ `streamlit run detectora.py`

- Gaussian Mixture Model (GMM)  
- Convolutional Neural Network (CNN)  
- Spectrograms  






demo clip:

